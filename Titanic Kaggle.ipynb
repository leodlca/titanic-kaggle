{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets and filters training data.\n",
    "wanted_columns = ['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']\n",
    "data = pd.read_csv('train.csv', usecols=wanted_columns)\n",
    "data = data.set_index('PassengerId')\n",
    "\n",
    "# Gets and filters testing data.\n",
    "wanted_test_columns = ['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']\n",
    "test_data = pd.read_csv('test.csv', usecols=wanted_test_columns)\n",
    "test_data_indexes = test_data['PassengerId']\n",
    "test_data = test_data.set_index('PassengerId')\n",
    "\n",
    "# Gets Y axis data.\n",
    "data_y = data['Survived']\n",
    "data_X = data.drop('Survived', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handles preprocessing\n",
    "\n",
    "def preprocess(train_X, test_X):\n",
    "    # Deals with NaN data containing rows.\n",
    "    imputer = Imputer()\n",
    "    NaN_containing_rows = ['Age', 'Fare']\n",
    "    train_X[NaN_containing_rows] = imputer.fit_transform(train_X[NaN_containing_rows])\n",
    "    test_X[NaN_containing_rows] = imputer.transform(test_X[NaN_containing_rows])\n",
    "    \n",
    "    # Uses log on skewed features to improve performance.\n",
    "    scaler = MinMaxScaler()\n",
    "    skewed = ['Fare']\n",
    "    train_X[skewed] = train_X[skewed].apply(lambda x: np.log(x + 1))\n",
    "    test_X[skewed] = test_X[skewed].apply(lambda x: np.log(x + 1))\n",
    "    \n",
    "    # Normalizes continuous features.\n",
    "    continuous = ['Age', 'Fare']\n",
    "    train_X[continuous] = scaler.fit_transform(train_X[continuous])\n",
    "    test_X[continuous] = scaler.transform(test_X[continuous])\n",
    "    \n",
    "    # One hot encodes categorical features.\n",
    "    categorical = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Embarked']\n",
    "    train_X = pd.get_dummies(train_X, columns=categorical)\n",
    "    test_X = pd.get_dummies(test_X, columns=categorical)\n",
    "    \n",
    "    # Handles with the different number of features.\n",
    "    missing_cols = set(train_X) - set(test_X)\n",
    "    for col in missing_cols:\n",
    "        test_X[col] = 0\n",
    "    test_X = test_X[train_X.columns]\n",
    "    \n",
    "    return train_X, test_X\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X = preprocess(data_X, test_data)\n",
    "\n",
    "# Splits train and test data to get model accuracy.\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, data_y, test_size=0.15)\n",
    "\n",
    "# Instantiates the models.\n",
    "dtc_model = DecisionTreeClassifier()\n",
    "lr_model = LogisticRegression()\n",
    "ada_model = AdaBoostClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Maps the models into an array of dictionaries with an attribute \"name\".\n",
    "models = [{'obj': dtc_model, 'name': 'Decision_Tree'}, \n",
    "          {'obj': lr_model, 'name': 'Logistic_Regression'}, \n",
    "          {'obj': ada_model, 'name': 'AdaBoost_EM'},\n",
    "          {'obj': rf_model, 'name': 'RandomForest_EM'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs the result in a csv file.\n",
    "def output_csv(prediction, name):\n",
    "    now = str(int(datetime.datetime.now().timestamp()))\n",
    "    dictionary = {\"Survived\": prediction, \"PassengerId\": test_data_indexes}\n",
    "    prediction_df = pd.DataFrame(dictionary)\n",
    "    prediction_df.to_csv(name + now + '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit, predict and get accuracy of the different models.\n",
    "def fit_predict_get_accuracy(model_obj, X_train, y_train, X_test, y_test, name):\n",
    "    model_obj.fit(X_train, y_train)    \n",
    "    \n",
    "    prediction = model_obj.predict(X_test)\n",
    "    prediction_accuracy_score = accuracy_score(y_test, prediction)      \n",
    "    \n",
    "    print(\"{} accuracy score: {}\".format(name, prediction_accuracy_score))\n",
    "    return prediction_accuracy_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision_Tree accuracy score: 0.8283582089552238\n",
      "Logistic_Regression accuracy score: 0.7985074626865671\n",
      "AdaBoost_EM accuracy score: 0.7985074626865671\n",
      "RandomForest_EM accuracy score: 0.8283582089552238\n",
      "The winner is: Decision_Tree!!!\n"
     ]
    }
   ],
   "source": [
    "# Executes the function in each model, gets the best of them and outputs a csv file.\n",
    "scores = []\n",
    "for model in models:\n",
    "    scores.append(fit_predict_get_accuracy(model['obj'], X_train, y_train, X_test, y_test, model['name']))\n",
    "    \n",
    "max_score = max(scores)\n",
    "max_score_index = scores.index(max_score)\n",
    "best_model = models[max_score_index]\n",
    "\n",
    "bm_prediction = best_model['obj'].predict(test_X)\n",
    "output_csv(bm_prediction, best_model['name'])\n",
    "\n",
    "print(\"The winner is: {}!!!\".format(best_model['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
